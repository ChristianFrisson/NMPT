<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<title>Nick&#39;s Machine Perception Toolbox: Nick&#39;s Machine Perception Toolbox</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<!-- Generated by Doxygen 1.7.2 -->
<div class="navigation" id="top">
  <div class="tabs">
    <ul class="tablist">
      <li class="current"><a href="main.html"><span>Main&#160;Page</span></a></li>
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
    </ul>
  </div>
</div>
<div class="header">
  <div class="headertitle">
<h1>Nick's Machine Perception Toolbox </h1>  </div>
</div>
<div class="contents">
<h3 class="version">0.4 </h3><h2><a class="anchor" id="intro_sec"></a>
Introduction</h2>
<div align="center">
<img src="NMPT_Logo_smallest.png" alt="NMPT_Logo_smallest.png"/>
</div>
 <p>The NMPT package consists of an API and a set of libraries for Machine Perception that were developed by Nicholas Butko. It can be obtained via the <a class="el" href="obtaining_page.html#obtaining_sec">Download NMPT</a> section. Directions for compiling the software (including platform-specific directions for installing OpenCV 2.1+) are in the <a class="el" href="install_page.html#install_sec">Installation</a> section. The central philosophy of this package is three-fold:</p>
<ul>
<li>Easy to Install </li>
<li>Easy to Learn API </li>
<li>Easy to Run</li>
</ul>
<p>The code is meant to stand alone under any standard C++ compiler, with the exception that it requires the OpenCV 2.1+ libraries. The only platform-specific (or user specific) portion of the compilation should be correctly locating the OpenCV libraries on your system. A few standard configurations are supported, but porting the code to a new system is as simple as modifying the Makefile to reflect the location of the OpenCV header files (includes) and libraries.</p>
<p>The core of the library is an API for <a class="el" href="group___m_p_group.html">Machine Perception Primitives</a>. There is also a separate API for the <a class="el" href="group___aux_group.html">Auxilliary Tools</a> used internally, which may also be useful to others.</p>
<p>The following <a class="el" href="group___m_p_group.html">Machine Perception Primitives</a> are currently implemented in this library / API: </p>
<ul>
<li><a class="el" href="class_fast_salience.html" title="  Machine Perception Primitive:   An implementation of the &quot;Fast Salience Using Natural-statisti...">FastSalience</a>: An implementation of the "Fast Salience Using Natural-statistics" algorithm from Butko et al., 2008. If this code is used in your research, please cite both the paper and this NMPT package. FastSUN is an efficient implementation of Zhang et al.'s SUN algorithm (see <a class="el" href="bib_page.html#bib_sec">Related Publications</a>). </li>
<li><a class="el" href="class_m_i_p_o_m_d_p.html" title="  Machine Perception Primitive:   An implementation of the &quot;Multinomial IPOMDP&quot; algorithm f...">MIPOMDP</a>: An implementation of the "Multinomial Infomax-POMDP" algorithm from Butko and Movellan, 2009. If this code is used in your research, please cite both the paper and this NMPT package. <a class="el" href="class_m_i_p_o_m_d_p.html" title="  Machine Perception Primitive:   An implementation of the &quot;Multinomial IPOMDP&quot; algorithm f...">MIPOMDP</a> is an extension of the IPOMDP Infomax Model of Eye-movment in Butko and Movellan, 2008; Najemnik and Geisler, 2005 (see <a class="el" href="bib_page.html#bib_sec">Related Publications</a>). </li>
<li><a class="el" href="class_gentle_boost_classifier.html" title="  Machine Perception Primitive:   An implementation of a GentleBoost classifier for image patch class...">GentleBoostClassifier</a> and <a class="el" href="class_gentle_boost_cascaded_classifier.html" title="  Machine Perception Primitive:   An implementation of a GentleBoost cascaded classifier for full ima...">GentleBoostCascadedClassifier</a>: An implementation of a fast approach to object detection, described in Fasel 2006 (see <a class="el" href="bib_page.html#bib_sec">Related Publications</a>). <a class="el" href="class_gentle_boost_classifier.html" title="  Machine Perception Primitive:   An implementation of a GentleBoost classifier for image patch class...">GentleBoostClassifier</a> is useful for two-way classification whole images (or image patches). <a class="el" href="class_gentle_boost_cascaded_classifier.html" title="  Machine Perception Primitive:   An implementation of a GentleBoost cascaded classifier for full ima...">GentleBoostCascadedClassifier</a> is useful for learning very efficient object detectors that search for objects in video in real time. </li>
<li><a class="el" href="class_internal_motion_model.html" title="  Machine Perception Primitive:   An implementation of a model that allows a robot to learn about its...">InternalMotionModel</a>: An implementation of the method described in Butko and Movellan, 2010 (see <a class="el" href="bib_page.html#bib_sec">Related Publications</a>) for allowing robots to learn how their eyes work.</li>
</ul>
<p>The <a class="el" href="group___examples_group.html">Example Programs</a> are meant to be both illustrative of code usage, and valuable stand-alone tools for research for those who don't wish to code their own programs using the API. The following examples are included:</p>
<p><b>Examples of <a class="el" href="class_fast_salience.html" title="  Machine Perception Primitive:   An implementation of the &quot;Fast Salience Using Natural-statisti...">FastSalience</a>:</b> </p>
<ul>
<li>simplesalience_page - The simplest program that illustrates the use of the <a class="el" href="class_fast_salience.html" title="  Machine Perception Primitive:   An implementation of the &quot;Fast Salience Using Natural-statisti...">FastSalience</a> class. One of the included movies is loaded into memory and processed frame-by-frame for salience. The result is displayed. To run:</li>
</ul>
<p><code>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; &gt;&gt;bin/SimpleSalienceExample</code></p>
<ul>
<li><a class="el" href="group___examples_group.html">FastSUN</a> - A more advanced program that in a visually rich way the default parameter set of the <a class="el" href="class_fast_salience.html" title="  Machine Perception Primitive:   An implementation of the &quot;Fast Salience Using Natural-statisti...">FastSalience</a> class. This program can take input from any video that OpenCV can read, or from an attached camera. It displays the input/output of the salience program, and timing information. To run:</li>
</ul>
<p><code>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; &gt;&gt;bin/FastSUN [optional-path-to-movie-file]</code></p>
<ul>
<li><a class="el" href="group___examples_group.html">FastSUN</a> - A program that illustrates the range of parameters that can control the <a class="el" href="class_fast_salience.html" title="  Machine Perception Primitive:   An implementation of the &quot;Fast Salience Using Natural-statisti...">FastSalience</a> class. This program can take input from any video that OpenCV can read, or from an attached camera. It displays the input/output of the salience program, and timing information. It has a user-interface where all of the parameters to the salience algorithm can be modified manually. To run:</li>
</ul>
<p><code>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; &gt;&gt;bin/FastSUN [optional-path-to-movie-file]</code></p>
<ul>
<li><a class="el" href="group___examples_group.html">FastSUNImage</a> - A similar example to the one above, this program analyzes a static image for salience. To run:</li>
</ul>
<p><code>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; &gt;&gt;bin/FastSUNImage [optional-path-to-image-file]</code></p>
<p><b>Examples of <a class="el" href="class_m_i_p_o_m_d_p.html" title="  Machine Perception Primitive:   An implementation of the &quot;Multinomial IPOMDP&quot; algorithm f...">MIPOMDP</a>:</b> </p>
<ul>
<li><a class="el" href="group___examples_group.html">SimpleFaceTracker</a> An example the simplest program using of the <a class="el" href="class_m_i_p_o_m_d_p.html" title="  Machine Perception Primitive:   An implementation of the &quot;Multinomial IPOMDP&quot; algorithm f...">MIPOMDP</a> class. Loads a video, and produces one fixation per video frame, tracking the face across video frames. To run:</li>
</ul>
<p><code>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; &gt;&gt; bin/SimpleFaceTracker</code></p>
<ul>
<li><a class="el" href="group___examples_group.html">FoveatedFaceTrackerImage</a> A more complete example of the <a class="el" href="class_m_i_p_o_m_d_p.html" title="  Machine Perception Primitive:   An implementation of the &quot;Multinomial IPOMDP&quot; algorithm f...">MIPOMDP</a> algorithm,: takes any image OpenCV reads as input, and animates visual search. To run:</li>
</ul>
<p><code>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; &gt;&gt; bin/FoveatedFaceTracker [optional-path-to-movie-file]</code></p>
<ul>
<li><a class="el" href="group___examples_group.html">FoveatedFaceTracker</a> A more complete example of the <a class="el" href="class_m_i_p_o_m_d_p.html" title="  Machine Perception Primitive:   An implementation of the &quot;Multinomial IPOMDP&quot; algorithm f...">MIPOMDP</a> algorithm, displaying visualizations of the algorithm internals, and taking multiple input sources (camera, video). To run:</li>
</ul>
<p><code>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; &gt;&gt; bin/FoveatedFaceTrackerImage [required-path-to-image-file]</code></p>
<ul>
<li><a class="el" href="group___examples_group.html">CVPRTestSpeed</a> - Reproduce the speed results from Butko and Movellan, CVPR 09 on your own machine. To run:</li>
</ul>
<p><code>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;</code>(1) Uncompress and Expand the included GENKI R2009a dataset. Make sure the GENKI-R2009a folder is in the data directory: <br/>
 <code>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; &gt;&gt; tar -xzvf data/GENKI-R2009a.tgz -C data/<br/>
 </code> <br/>
 <code>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;</code>(2) Run the program.<br/>
 <code>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; &gt;&gt; bin/CVPRTestSpeed</code></p>
<ul>
<li><a class="el" href="group___examples_group.html">CVPRTrainModels</a> - Reproduce the Multinomial Observation Models used to generate results in Butko and Movellan, CVPR 09 on your own machine. This file is included for instructional purposes -- the files that it creates are already included in the data directory (data/MIPOMDPData-21x21-4Scales-*.txt). To run:</li>
</ul>
<p><code>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;</code>(1) Uncompress and Expand the included GENKI R2009a dataset. Make sure the GENKI-R2009a folder is in the data directory: <br/>
 <code>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; &gt;&gt; tar -xzvf data/GENKI-R2009a.tgz -C data/ </code></p>
<p><code>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;</code>(2) Run the program.<br/>
 <code>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; &gt;&gt; bin/CVPRTrainModels</code></p>
<ul>
<li><a class="el" href="group___examples_group.html">TrainNarrowFOVModel</a> - Reproduce the Multinomial Observation Model used in the FoveatedFaceTracker example. This model has a narrow field of view, so that it cannot access the whole image at once. This illustrates how <a class="el" href="class_m_i_p_o_m_d_p.html" title="  Machine Perception Primitive:   An implementation of the &quot;Multinomial IPOMDP&quot; algorithm f...">MIPOMDP</a> can be used to simulate an active camera. This file is included for instructional purposes -- the files that it creates are already included in the data directory (data/MIPOMDPData-21x21-3Scales-*.txt). To run:</li>
</ul>
<p><code>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;</code>(1) Uncompress and Expand the included GENKI R2009a dataset. Make sure the GENKI-R2009a folder is in the data directory: <br/>
 <code>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; &gt;&gt; tar -xzvf data/GENKI-R2009a.tgz -C data/ </code></p>
<p><code>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;</code>(2) Run the program.<br/>
 <code>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; &gt;&gt; bin/TrainNarrowFOVModel</code></p>
<h3><a class="anchor" id="acknowledge_sec"></a>
Acknowledgements</h3>
<p>This work was supported by the National Science Foundation (NSF) Grant # <code>NSF ECS-0622229</code> </p>
</div>
<hr class="footer"/><address class="footer"><small>Generated on Thu Dec 9 2010 16:05:47 for Nick's Machine Perception Toolbox by&#160;
<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.7.2 </small></address>
</body>
</html>
